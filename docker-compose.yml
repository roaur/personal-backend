services:
  postgres:
    image: postgres:17
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/postgres.conf:/etc/postgresql/postgresql.conf
    command: [ "postgres", "-c", "config_file=/etc/postgresql/postgresql.conf" ]
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 5s
      timeout: 5s
      retries: 5

  pgbouncer:
    image: edoburu/pgbouncer
    restart: always
    environment:
      DB_USER: ${POSTGRES_USER}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_HOST: postgres
      DB_NAME: ${POSTGRES_DB}
      AUTH_TYPE: plain
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 1000
      DEFAULT_POOL_SIZE: 20
      LISTEN_PORT: 6432
    ports:
      - "6432:6432"
    depends_on:
      postgres:
        condition: service_healthy

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"

  fastapi:
    build:
      context: .
      dockerfile: fastapi/Dockerfile
    restart: always
    env_file: .env
    environment:
      POSTGRES_HOST: pgbouncer
      POSTGRES_PORT: 6432
      SQLALCHEMY_DATABASE_URL: postgresql+psycopg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@pgbouncer:6432/${POSTGRES_DB}
    depends_on:
      pgbouncer:
        condition: service_started
      postgres:
        condition: service_healthy
    volumes:
      - ./fastapi:/app
      - ./shared:/app/shared
    ports:
      - "8000:8000"

  celery_producer:
    build:
      context: .
      dockerfile: worker/Dockerfile
    restart: always
    # Concurrency 1 for Rate Limiting
    command: celery -A worker.tasks worker -Q api_queue,celery --loglevel=info --concurrency=1 --hostname=producer@%h
    env_file: .env
    environment:
      PYTHONPATH: /app
      POSTGRES_HOST: pgbouncer
      POSTGRES_PORT: 6432
    depends_on:
      - redis
      - pgbouncer
    volumes:
      - ./worker:/app/worker
      - ./shared:/app/shared

  celery_consumer:
    build:
      context: .
      dockerfile: worker/Dockerfile
    restart: always
    # Concurrency 8 for Parallel Processing
    command: celery -A worker.tasks worker -Q db_queue --loglevel=info --concurrency=8 --hostname=consumer@%h
    env_file: .env
    environment:
      PYTHONPATH: /app
      POSTGRES_HOST: pgbouncer
      POSTGRES_PORT: 6432
    depends_on:
      - redis
      - pgbouncer
    volumes:
      - ./worker:/app/worker
      - ./shared:/app/shared

  celery_analysis:
    build:
      context: .
      dockerfile: worker/Dockerfile
    restart: always
    # Concurrency 1 for Analysis (DuckDB is single-threaded per connection usually, and we want to avoid contention)
    command: celery -A worker.tasks worker -Q analysis_queue --loglevel=info --concurrency=1 --hostname=analysis@%h
    env_file: .env
    environment:
      PYTHONPATH: /app
      POSTGRES_HOST: pgbouncer
      POSTGRES_PORT: 6432
    depends_on:
      - redis
      - pgbouncer
    volumes:
      - ./worker:/app/worker
      - ./shared:/app/shared

  celery_beat:
    build:
      context: .
      dockerfile: worker/Dockerfile
    restart: always
    command: celery -A worker.tasks beat --loglevel=info
    env_file: .env
    environment:
      PYTHONPATH: /app
      POSTGRES_HOST: pgbouncer
      POSTGRES_PORT: 6432
    depends_on:
      - redis
      - pgbouncer
    volumes:
      - ./worker:/app/worker
      - ./shared:/app/shared

volumes:
  postgres_data:


